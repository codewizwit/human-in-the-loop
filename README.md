# ğŸŒ­ Human in the Loop

**Centralized repository and governance system for AI productivity tools**

A developer-first toolkit for managing Claude prompts, agents, context packs, and evaluators with standardization, quality control, and visibility.

---

## Why This Exists

AI productivity tools are transforming how we build software, but without centralized governance, we risk inconsistency, duplication, and quality drift. Human in the Loop solves this by creating a single source of truth for all AI tooling.

**The problem:**

- Prompts and agents scattered across repos, Slack threads, and local files
- No standardization means teams reinvent the wheel with different patterns
- Zero visibility into what works, what's adopted, or what needs improvement
- Quality concerns with no review process for AI tools

**The solution:**

- Single repository where all AI productivity tools are discoverable, versioned, and governed
- Standardized contribution workflow that ensures quality and consistency
- Clear metrics on tool adoption and effectiveness
- Developer-friendly CLI that makes it easy to find, install, and use AI tools

---

## Quick Start

Install the CLI:

```bash
npm install -g @human-in-the-loop/cli
```

Or use npx:

```bash
npx hitl --version
```

Search for prompts:

```bash
hitl search "code review"
```

Install a prompt:

```bash
hitl install prompt/code-review-ts
```

---

## What's Inside

### ğŸ“š Prompt Library (`/toolkit/prompts`)

Production-ready prompts organized by use case, versioned and quality-assured. Each prompt includes metadata, usage examples, and expected outputs.

### ğŸ¤– Agent Registry (`/toolkit/agents`)

Catalog of AI agents with their configurations, capabilities, and integration guides. Includes performance benchmarks and cost estimates.

### ğŸ¯ Context Packs (`/toolkit/context-packs`)

Framework-specific knowledge bases that provide agents with deep technical context:

- **Angular**: Component patterns, routing, state management, testing
- **NestJS**: Module structure, dependency injection, middleware, guards
- **CI/CD**: Pipeline patterns, deployment strategies, environment configs

### âœ… Evaluators (`/toolkit/evaluators`)

Quality assurance tools that validate AI outputs against defined criteria like code quality, documentation completeness, security, and performance.

### ğŸ›¡ï¸ Guardrails (`/toolkit/guardrails`)

Safety mechanisms that enforce responsible AI usage, including input validation, output filtering, rate limiting, and audit logging.

### âš¡ CLI Tool (`/src/cli`)

Developer-friendly command-line interface for discovering, installing, and managing AI tools.

### ğŸ›¡ï¸ Governance (`/src/governance`)

Contribution validation and quality assurance tooling that ensures all contributions meet project standards.

---

## Repository Structure

```
human-in-the-loop/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ cli/                     # TypeScript CLI tool
â”‚   â””â”€â”€ governance/              # Contribution validation tooling
â”œâ”€â”€ toolkit/
â”‚   â”œâ”€â”€ prompts/                 # Shared prompt library
â”‚   â”œâ”€â”€ agents/                  # Agent definitions and configs
â”‚   â”œâ”€â”€ evaluators/              # Quality evaluation tools
â”‚   â”œâ”€â”€ guardrails/              # Safety and governance rules
â”‚   â””â”€â”€ context-packs/           # Framework-specific context
â”‚       â”œâ”€â”€ angular/             # Angular-specific context
â”‚       â”œâ”€â”€ nestjs/              # NestJS-specific context
â”‚       â””â”€â”€ ci-cd/               # CI/CD patterns and configs
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ getting-started.md       # Installation and first steps
â”‚   â”œâ”€â”€ ai-best-practices.md     # Responsible AI usage guidelines
â”‚   â”œâ”€â”€ toolkit-usage.md         # Using prompts, agents, evaluators
â”‚   â”œâ”€â”€ contributing-guidelines.md # Detailed contribution workflow
â”‚   â”œâ”€â”€ governance-model.md      # Quality and review process
â”‚   â””â”€â”€ architecture.md          # System design overview
â””â”€â”€ PLANNING.md                  # Full design proposal
```

---

## CLI Commands

```bash
# Search for prompts and agents
hitl search [query]

# Install a prompt or agent
hitl install [tool]

# Validate local setup
hitl doctor

# Submit a new tool
hitl contribute [type] [path]

# View usage analytics
hitl stats
```

---

## Contributing

We welcome contributions! Please see [CONTRIBUTING.md](./CONTRIBUTING.md) for guidelines on:

- Submitting new prompts and agents
- Quality standards and review process
- Testing requirements
- Documentation expectations

All code must include TypeDoc comments above functions (no inline comments) and follow our TypeScript strict mode standards.

---

## Documentation

- [Getting Started](./docs/getting-started.md) - Installation, setup, and your first prompt
- [AI Best Practices](./docs/ai-best-practices.md) - Responsible AI usage and prompt engineering
- [Toolkit Usage](./docs/toolkit-usage.md) - Using prompts, agents, evaluators, and guardrails
- [Contributing Guidelines](./docs/contributing-guidelines.md) - Detailed contribution workflow
- [Governance Model](./docs/governance-model.md) - Quality review and release process
- [Architecture](./docs/architecture.md) - System design and technical overview

For the full design proposal, see [PLANNING.md](./PLANNING.md).

---

## Technology Stack

- **Build System**: Nx monorepo
- **Language**: TypeScript (strict mode)
- **Package Manager**: pnpm
- **CLI Framework**: Commander.js
- **Validation**: Zod
- **Testing**: Vitest

---

## License

MIT License - see [LICENSE](./LICENSE) for details

---

## About

**Human-in-the-Loop by codewizwit**
Build with care. Ship with purpose.

For issues and feature requests, please use [GitHub Issues](https://github.com/codewizwit/human-in-the-loop/issues).
